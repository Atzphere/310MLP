{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f0d58-3ded-4584-a435-8b637846b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import tqdm.keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e27fb-0892-459a-a24b-ccd46126fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(mini, maxi, maxsub, num):\n",
    "    numbers = []\n",
    "    y = []\n",
    "    features = []\n",
    "    for i in range(num):\n",
    "        arr1 = np.random.randint(mini, maxi, size=(np.random.randint(1, maxsub)))\n",
    "        numbers.append(arr1)\n",
    "        features.append(np.array((np.sqrt(arr1), arr1**2)))\n",
    "        y.append(arr1.sum())\n",
    "    return features, np.array(y), numbers\n",
    "\n",
    "def make_easyset(num_instances, min_comps, max_comps):\n",
    "    comps = [] # features\n",
    "    pair_sums = [] # true reconstructed\n",
    "    sums = [] # y\n",
    "\n",
    "    for i in range(num_instances):\n",
    "        arr1 = np.random.randint(1, 10, size=(np.random.randint(1, max_comps), 2))\n",
    "        comps.append(np.array(arr1))\n",
    "        pair_sums.append(arr1.sum(axis=-1))\n",
    "        sums.append(arr1.sum())\n",
    "    return comps, np.array(sums), pair_sums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45b6a1-e521-4c32-972c-38633056f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(keras.Model):\n",
    "    def __init__(self, n_inputs, layers, output_func=\"linear\"):\n",
    "        super().__init__()\n",
    "        # subnetwork used to evaluate atomic potential contributions, evaluated for each atom in a structure.\n",
    "        self.subnet = keras.Sequential(layers=[\n",
    "            keras.Input(shape=(n_inputs,))]  # input layer takes in n_inputs number of symmetry function features\n",
    "            + layers\n",
    "            + [keras.layers.Dense(1, activation=output_func)])  # output layer returns individual energy contributions\n",
    "        self.num_features = n_inputs\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        '''\n",
    "        feed-forward method for the model\n",
    "        should have the signature we ultimately want the model to have,\n",
    "        i.e. for one structure: Tensor[StructureFeatures] -> Energy_total\n",
    "\n",
    "        which then for multiple structures:\n",
    "            Tensor[Tensor[StructureFeatures]] -> Tensor[Energy_total]\n",
    "\n",
    "        wherein in reality the outermost Tensor is just a list.\n",
    "\n",
    "        inputs: shape (num_atoms, num_features) tensor\n",
    "\n",
    "        (None, None, 2)\n",
    "\n",
    "        features: number of numbers, average of numbers\n",
    "        '''\n",
    "\n",
    "        #  subnet.call(Tensor[StructureFeatures]) -> Tensor[EnergyContributions]\n",
    "\n",
    "        numsum = []\n",
    "\n",
    "        def process_struct(struct):\n",
    "            return self.subnet(struct, training=training)\n",
    "\n",
    "        pairwise_contribs = tf.map_fn(process_struct, inputs, fn_output_signature=tf.RaggedTensorSpec(ragged_rank=0))\n",
    "        numsum.append(tf.reduce_sum(pairwise_contribs, axis=1))\n",
    "\n",
    "        return numsum\n",
    "\n",
    "class GlobalProgressBar(keras.callbacks.Callback):\n",
    "    def __init__(self, total_epochs, total_batches):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.total_batches = total_batches\n",
    "        self.progress_bar = tqdm(total=total_epochs * total_batches, desc=\"Training Progress\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.progress_bar.update(1)  # Update per batch\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49328301-03ea-4325-974d-c059249ea988",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, sums, trues = make_dataset(1, 20, 5, 1000)\n",
    "stacked = np.hstack(features).T\n",
    "\n",
    "SSC = StandardScaler().fit(stacked)\n",
    "\n",
    "scaled_features = [SSC.transform(struct.T) for struct in features]\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, truetrain, truetest = train_test_split(scaled_features, sums, trues, test_size=0.4)\n",
    "Xval, Xtest, yval, ytest, trueval, truetest = train_test_split(Xtest, ytest, truetest, test_size=0.5)\n",
    "\n",
    "Xtrain = tf.ragged.constant(Xtrain, ragged_rank=1, inner_shape=(2,))\n",
    "Xval = tf.ragged.constant(Xval, ragged_rank=1, inner_shape=(2,))\n",
    "Xtest = tf.ragged.constant(Xtest, ragged_rank=1, inner_shape=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be690f70-bf8a-4132-aabc-6bbe7bf08d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1 = MLP(n_inputs=2, layers=[keras.layers.Dense(100, activation=\"relu\"), keras.layers.Dense(100, activation=\"relu\")])\n",
    "\n",
    "MLP1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "print(Xtrain.shape)\n",
    "\n",
    "epochs=400\n",
    "batch_size = 20\n",
    "total_batches = Xtrain.shape[0] // batch_size\n",
    "\n",
    "res = MLP1.fit(\n",
    "    Xtrain, ytrain,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = (Xval, yval),\n",
    "    verbose = 0,\n",
    "    callbacks=[tqdm.keras.TqdmCallback()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261c18c-afe7-4f0f-a5a4-a4f2518b69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest - MLP1.predict(Xtest)[0].flatten()\n",
    "print(MLP1.subnet.predict(Xtrain)[0])\n",
    "print(truetrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd0cce-ac85-42c8-af5f-a45a029806ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, y_contrib = make_dataset(0, 25, 54, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13cec02-bfd3-48db-92d1-e58323dd1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the input with ragged=True\n",
    "input_layer = keras.Input(shape=(None, 10), ragged=True)\n",
    "\n",
    "# Example: Use a Masking layer (optional, depending on the architecture)\n",
    "x = layers.Masking(mask_value=0.0)(input_layer)  \n",
    "\n",
    "# Example: Process with a LSTM layer\n",
    "x = layers.LSTM(32)(x)\n",
    "\n",
    "# Output layer\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Define the model\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b74e43-4f93-4355-a954-1791ca554105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create example ragged data (N_instances=3, variable sequence lengths)\n",
    "ragged_data = tf.ragged.constant([\n",
    "    np.random.rand(3, 10),  # 3 timesteps\n",
    "    np.random.rand(5, 10),  # 5 timesteps\n",
    "    np.random.rand(2, 10)   # 2 timesteps\n",
    "], ragged_rank=1)\n",
    "\n",
    "print(ragged_data.shape)\n",
    "\n",
    "# Example labels\n",
    "labels = np.array([0, 1, 0])  # Binary classification labels\n",
    "\n",
    "# Train the model\n",
    "print(tf.unstack(ragged_data, axis = 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
